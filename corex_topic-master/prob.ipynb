{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import corextopic.corextopic as ct\n",
    "import corextopic.vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sys\n",
    "import csv\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121649\n"
     ]
    }
   ],
   "source": [
    "# load the data from file\n",
    "def load_csv(filename):\n",
    "    res = []\n",
    "    data = pd.read_csv(filename, encoding='utf-8')\n",
    "    votes = []\n",
    "    actual_rating = []\n",
    "    customer_id = []\n",
    "    review_id = []\n",
    "    for line in data.values:\n",
    "        res.append(str(line[13]).lower())\n",
    "        votes.append((int(line[8]), int(line[9] - int(line[8]))))\n",
    "        actual_rating.append(int(line[7]))\n",
    "        customer_id.append(line[1])\n",
    "        review_id.append(line[2])\n",
    "    return res, votes, actual_rating, customer_id, review_id\n",
    "\n",
    "\n",
    "# data, votes, actual_rating, customer_id, review_id = load_csv(\"electronics_votes10more_reviews.csv\")\n",
    "# print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"amazon_reviews_us_Electronics_v1_00.tsv\", sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091024\n"
     ]
    }
   ],
   "source": [
    "# load the data from file\n",
    "def load_tsv(filename):\n",
    "    res = []\n",
    "    data = pd.read_csv(filename, encoding='utf-8', sep='\\t', on_bad_lines='skip')\n",
    "    votes = []\n",
    "    actual_rating = []\n",
    "    customer_id = []\n",
    "    review_id = []\n",
    "    for line in data.values:\n",
    "        res.append(str(line[13]).lower())\n",
    "        votes.append((int(line[8]), int(line[9] - int(line[8]))))\n",
    "        actual_rating.append(int(line[7]))\n",
    "        customer_id.append(line[1])\n",
    "        review_id.append(line[2])\n",
    "    return res, votes, actual_rating, customer_id, review_id\n",
    "\n",
    "data, votes, actual_rating, customer_id, review_id = load_tsv(\"amazon_reviews_us_Electronics_v1_00.tsv\")\n",
    "print(len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "data = pd.read_stata(\"yelp.dta\")\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_json(filename):\n",
    "    res = []\n",
    "    file = open(filename)\n",
    "    data = json.load(file)\n",
    "    for i in data:\n",
    "        res.append(i[\"review\"])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3091024, 20000)\n",
      "(3091024, 19518)\n"
     ]
    }
   ],
   "source": [
    "data, votes, actual_rating, customer_id, review_id = load_tsv(\"amazon_reviews_us_Electronics_v1_00.tsv\")\n",
    "# vectorize the words in the articles into binary\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(data)\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "print(doc_word.shape)\n",
    "\n",
    "\n",
    "num_topic = 10\n",
    "# get all the words\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "\n",
    "# get rid of all the digits\n",
    "not_digit_inds = [ind for ind,word in enumerate(words) if not word.isdigit()]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words    = [word for ind,word in enumerate(words) if not word.isdigit()]\n",
    "\n",
    "print(doc_word.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load keywords\n",
    "anchor_words = []\n",
    "fh = open(\"Initial Keywords Electronics 2.txt\")\n",
    "anchor = fh.readlines()\n",
    "for i in range(len(anchor)):\n",
    "    if i % 3 == 1:\n",
    "        anchor_words.append(anchor[i].rstrip(\"\\n\").split(\" \"))\n",
    "\n",
    "len(anchor_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Anchor word not in word column labels provided to CorEx: recyko\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: twelve\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: w\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: x\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: he560\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: a161p\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: xpt100\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: system\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: cry\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: keystroke\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: ma900\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: frill\n",
      "WARNING: Anchor word not in word column labels provided to CorEx: besides\n",
      "0: bought, purchased, pair, year, ordered, cost, month, paid, owned, lasted\n",
      "1: br, just, like, don, use, music, ve, want, way, using\n",
      "2: tv, cable, hdmi, receiver, connect, setup, connected, input, output, hooked\n",
      "3: listen, wife, son, daughter, husband, sitting, bed, morning, walking, walk\n",
      "4: time, battery, turn, second, button, setting, alarm, mode, press, turning\n",
      "5: sound, bass, clarity, treble, mids, distortion, headphones, muddy, midrange, reproduction\n",
      "6: plastic, rubber, slip, headband, housing, bend, earpiece, silicone, strap, bent\n",
      "7: quality, good, price, really, better, overall, nice, looking, think, look\n",
      "8: product, company, customer, seller, manufacturer, contacted, sorry, email, exchange, vendor\n",
      "9: mp3, software, download, itunes, file, format, library, downloaded, podcasts, content\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set the number of topics to be 10\n",
    "topic_model = ct.Corex(n_hidden=num_topic, words=words, max_iter=2000, verbose=False, seed=1)\n",
    "topic_model.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=10)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = topic_model.predict_proba(doc_word)[0]\n",
    "\n",
    "\n",
    "L = []\n",
    "L.append([\"customer_id\", \"review_id\", \"actual_rating\", \"upvote\", \"down_vote\", \"original_content\", \"prob_a1\", \"prob_a2\", \"prob_a3\", \"prob_a4\", \"prob_a5\", \"prob_a6\", \"prob_a7\", \"prob_a8\", \"prob_a9\", \"prob_a10\", \"entropy\", \"length\"])\n",
    "for i in range(3091024):\n",
    "    LL = []\n",
    "    LL.append(customer_id[i])\n",
    "    LL.append(review_id[i])\n",
    "    LL.append(actual_rating[i])\n",
    "    LL.append(votes[i][0])\n",
    "    LL.append(votes[i][1])\n",
    "    LL.append(data[i])\n",
    "    for probaility in prob[i]:\n",
    "        #LL.append(\"%.4f\" % (probaility*100) + \"%\" + \"  \")\n",
    "        LL.append(probaility)\n",
    "    ent = entropy(prob[i], base=2)\n",
    "    LL.append(ent)\n",
    "    LL.append(len(data[i].split()))\n",
    "    \n",
    "\n",
    "    L.append(LL)\n",
    "\n",
    "with open('electronics_review_seed2.csv', 'a+', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(L)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091024, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"electronics_review_seed2.csv\", on_bad_lines='skip')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3091024, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_json(\"yelp.json\")\n",
    "# vectorize the words in the articles into binary\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(data)\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "\n",
    "num_topic = 9\n",
    "# get all the words\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "\n",
    "# get rid of all the digits\n",
    "not_digit_inds = [ind for ind,word in enumerate(words) if not word.isdigit()]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words    = [word for ind,word in enumerate(words) if not word.isdigit()]\n",
    "\n",
    "# set the number of topics to be 10\n",
    "topic_model = ct.Corex(n_hidden=num_topic, words=words, max_iter=2000, verbose=False, seed=1)\n",
    "topic_model.fit(doc_word, words=words)\n",
    "\n",
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ', '.join(topic_words))\n",
    "\n",
    "prob = topic_model.predict_proba(doc_word)[0]\n",
    "print(prob)\n",
    "\n",
    "\n",
    "L = []\n",
    "L.append([\"Review\", \"prob_a1\", \"prob_a2\", \"prob_a3\", \"prob_a4\", \"prob_a5\", \"prob_a6\", \"prob_a7\", \"prob_a8\", \"prob_a9\", \"entropy\", \"length\"])\n",
    "for i in range(939580):\n",
    "    LL = []\n",
    "    LL.append(data[i])\n",
    "    for probaility in prob[i]:\n",
    "        #LL.append(\"%.4f\" % (probaility*100) + \"%\" + \"  \")\n",
    "        LL.append(probaility)\n",
    "    ent = entropy(prob[i], base=2)\n",
    "    LL.append(ent)\n",
    "    LL.append(len(data[i].split()))\n",
    "    \n",
    "\n",
    "    L.append(LL)\n",
    "\n",
    "with open('yelp.csv', 'a+', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(L)\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234.5元人民币可以兑换179.74美元\n"
     ]
    }
   ],
   "source": [
    "exchange_rate = 0.1456\n",
    "\n",
    "rmb_amount = float(input(\"请输入人民币金额：\")[:-1])\n",
    "usd_amount = rmb_amount * exchange_rate\n",
    "\n",
    "print(\"{}元人民币可以兑换{:.2f}美元\".format(rmb_amount, usd_amount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 111 121 131 141 \n",
      "151 161 171 181 191 \n"
     ]
    }
   ],
   "source": [
    "a = int(input(\"输入a\"))\n",
    "b = int(input(\"输入b\"))\n",
    "\n",
    "res = []  # 记录所有回文数\n",
    "for i in range(a, b+1): \n",
    "    if str(i) == str(i)[::-1]:\n",
    "        res.append(str(i))\n",
    "\n",
    "count = 0 #设置初始计数\n",
    "for j in range(len(res)):\n",
    "    print(res[j], end=' ')\n",
    "    count += 1 #开始计数\n",
    "    if count % 5 == 0: #每5个换行\n",
    "        print(end='\\n')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_password_strength(password):\n",
    "    contain_big_letter = False\n",
    "    contain_small_letter = False\n",
    "    contain_number = False\n",
    "    contain_symbol = False\n",
    "    longer_than_8 = False\n",
    "\n",
    "    for letter in \"ABCDEFGIJKLMNOPQRSTUVWXYZ\":\n",
    "        if letter in password:\n",
    "            contain_big_letter = True\n",
    "\n",
    "    for letter in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        if letter in password:\n",
    "            contain_small_letter = True\n",
    "\n",
    "    for number in \"0123456789\":\n",
    "        if number in password:\n",
    "            contain_number = True\n",
    "\n",
    "    for symbol in '.,/!;:?<>':\n",
    "        if symbol in password:\n",
    "            contain_symbol = True\n",
    "\n",
    "    if len(password) >= 8:\n",
    "        longer_than_8 = True\n",
    "\n",
    "    res = [contain_big_letter, contain_small_letter, contain_number, contain_symbol, longer_than_8]\n",
    "\n",
    "    return res.count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_password_strength(\"P123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vxqgdb'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def caesar_cipher(offset):\n",
    "    offset = offset % 26  # 确保偏移量在0到25之间\n",
    "\n",
    "    # 生成字母表\n",
    "    uppercase_letters = [chr(ord('A') + i) for i in range(26)]\n",
    "    lowercase_letters = [chr(ord('a') + i) for i in range(26)]\n",
    "\n",
    "    # 根据偏移量生成加密字母表\n",
    "    shifted_uppercase = uppercase_letters[offset:] + uppercase_letters[:offset]\n",
    "    shifted_lowercase = lowercase_letters[offset:] + lowercase_letters[:offset]\n",
    "\n",
    "    # 创建字母映射字典\n",
    "    mapping = {}\n",
    "    for i in range(26):\n",
    "        mapping[uppercase_letters[i]] = shifted_uppercase[i]\n",
    "        mapping[lowercase_letters[i]] = shifted_lowercase[i]\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def encrypt():\n",
    "    offset = int(input(\"请输入偏移数目: \"))\n",
    "    sentence = input(\"输入明文: \").lower()\n",
    "    mapping = caesar_cipher(offset)\n",
    "    res = []\n",
    "    for letter in sentence:\n",
    "        res.append(mapping[letter])\n",
    "    return \"\".join(res)\n",
    "\n",
    "encrypt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
